"""
Grounding DINO Detection Model Manager
Grounding DINO í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ê°ì²´ íƒì§€ ëª¨ë¸ ê´€ë¦¬ì
Hugging Face Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
"""
import torch
import logging
import numpy as np
from typing import Dict, Any, Optional, List
from PIL import Image
from fastapi import HTTPException

from ..base_model import BaseModel, ModelType, TaskType

logger = logging.getLogger(__name__)


class GroundingDINOManager(BaseModel):
    """
    Grounding DINO ê°ì²´ íƒì§€ ëª¨ë¸ ê´€ë¦¬ì
    í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•œ zero-shot ê°ì²´ íƒì§€
    Hugging Face Hubì—ì„œ ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ
    """

    def __init__(self):
        """Grounding DINO ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        super().__init__()
        self.model_type = ModelType.DETECTION
        self.task_type = TaskType.BBOX
        self.processor = None
        self.model_id = None

    def load_model(self, model_path: str = None, **kwargs):
        """
        Grounding DINO ëª¨ë¸ ë¡œë”© (Hugging Face Hub)

        Args:
            model_path (str, optional): Hugging Face model ID
                (ê¸°ë³¸ê°’: "IDEA-Research/grounding-dino-tiny")
            **kwargs:
                - model_id (str): ëª¨ë¸ ID (model_path ëŒ€ì‹  ì‚¬ìš© ê°€ëŠ¥)
        """
        try:
            # Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
            try:
                from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection
            except ImportError:
                raise ImportError(
                    "transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                    "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install transformers"
                )

            # ëª¨ë¸ ID ê²°ì • (ìš°ì„ ìˆœìœ„: kwargs['model_id'] > model_path > ê¸°ë³¸ê°’)
            self.model_id = kwargs.get('model_id') or model_path or "IDEA-Research/grounding-dino-tiny"

            logger.info(f"ğŸ”„ Grounding DINO ëª¨ë¸ ë¡œë”© ì‹œì‘")
            logger.info(f"  - Model ID: {self.model_id}")
            logger.info(f"  - Source: Hugging Face Hub")

            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            device = "cuda" if torch.cuda.is_available() else "cpu"
            logger.info(f"  - Device: {device}")

            # Processorì™€ ëª¨ë¸ ë¡œë“œ
            logger.info(f"ğŸ“¥ Processor ë‹¤ìš´ë¡œë“œ ì¤‘...")
            self.processor = AutoProcessor.from_pretrained(self.model_id)

            logger.info(f"ğŸ“¥ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            self.model = AutoModelForZeroShotObjectDetection.from_pretrained(self.model_id)

            # GPUë¡œ ì´ë™
            self.model.to(device)

            if device == "cuda":
                logger.info(f"âœ… Grounding DINO ëª¨ë¸ì„ GPUë¡œ ë¡œë“œ")
            else:
                logger.info(f"âœ… Grounding DINO ëª¨ë¸ì„ CPUë¡œ ë¡œë“œ")

            self.is_loaded = True
            logger.info(f"âœ… Grounding DINO ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

            return {
                "success": True,
                "message": f"Grounding DINO model loaded successfully from Hugging Face",
                "model_id": self.model_id,
                "supports_text_prompt": True,
                "device": device
            }

        except Exception as e:
            logger.error(f"âŒ Grounding DINO ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")

    def predict(self, image, **kwargs) -> Dict[str, Any]:
        """
        Grounding DINO ê°ì²´ íƒì§€ ì¶”ë¡  (Transformers API)

        Args:
            image: PIL Image ë˜ëŠ” numpy array
            **kwargs:
                - text_prompt (str): íƒì§€í•  ê°ì²´ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ (ì˜ˆ: "person. car. dog.")
                - box_threshold (float): ë°•ìŠ¤ ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.3)
                - text_threshold (float): í…ìŠ¤íŠ¸ ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.25)

        Returns:
            Dict[str, Any]: íƒì§€ ê²°ê³¼
        """
        if not self.validate_model():
            raise HTTPException(status_code=400, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # í•„ìˆ˜ íŒŒë¼ë¯¸í„° í™•ì¸
            text_prompt = kwargs.get('text_prompt')
            if not text_prompt:
                raise ValueError("text_promptê°€ í•„ìš”í•©ë‹ˆë‹¤ (ì˜ˆ: 'person. car. dog.')")

            box_threshold = kwargs.get('box_threshold', 0.3)
            text_threshold = kwargs.get('text_threshold', 0.25)

            logger.info(f"ğŸ” Grounding DINO ì¶”ë¡  ì‹œì‘")
            logger.info(f"  - í”„ë¡¬í”„íŠ¸: {text_prompt}")
            logger.info(f"  - Box threshold: {box_threshold}")
            logger.info(f"  - Text threshold: {text_threshold}")

            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            if not isinstance(image, Image.Image):
                if isinstance(image, np.ndarray):
                    image = Image.fromarray(image)
                else:
                    raise ValueError("ì´ë¯¸ì§€ëŠ” PIL Image ë˜ëŠ” numpy arrayì—¬ì•¼ í•©ë‹ˆë‹¤")

            # RGB ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')

            # Processorë¡œ ì…ë ¥ ì „ì²˜ë¦¬
            device = next(self.model.parameters()).device

            # Transformers ë²„ì „ í™•ì¸
            import transformers
            logger.info(f"ğŸ” Transformers ë²„ì „: {transformers.__version__}")

            inputs = self.processor(
                images=image,
                text=text_prompt,
                return_tensors="pt"
            ).to(device)

            # ì¶”ë¡ 
            with torch.no_grad():
                outputs = self.model(**inputs)

            # í›„ì²˜ë¦¬ (Transformers API)
            # ë²„ì „ì— ë”°ë¼ threshold íŒŒë¼ë¯¸í„° ì§€ì› ì—¬ë¶€ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ

            # API ì‹œê·¸ë‹ˆì²˜ í™•ì¸
            import inspect
            sig = inspect.signature(self.processor.post_process_grounded_object_detection)
            logger.info(f"ğŸ” post_process_grounded_object_detection íŒŒë¼ë¯¸í„°: {list(sig.parameters.keys())}")

            try:
                # ìµœì‹  ë²„ì „: box_threshold, text_threshold ì§€ì›
                logger.info(f"ğŸ”„ ìµœì‹  ë²„ì „ API ì‹œë„ ì¤‘ (box_threshold={box_threshold}, text_threshold={text_threshold})")
                results = self.processor.post_process_grounded_object_detection(
                    outputs,
                    inputs.input_ids,
                    box_threshold=box_threshold,
                    text_threshold=text_threshold,
                    target_sizes=[image.size[::-1]]
                )[0]

                logger.info("âœ… ìµœì‹  ë²„ì „ API ì„±ê³µ")

                # ê²°ê³¼ ë³€í™˜
                detections = self._postprocess_results(
                    boxes=results["boxes"],
                    scores=results["scores"],
                    labels=results["labels"],
                    image_size=image.size
                )

            except TypeError as e:
                # êµ¬ë²„ì „: threshold íŒŒë¼ë¯¸í„° ë¯¸ì§€ì› - ìˆ˜ë™ í•„í„°ë§
                logger.warning(f"Threshold íŒŒë¼ë¯¸í„° ë¯¸ì§€ì› - ìˆ˜ë™ í•„í„°ë§ ì‚¬ìš©: {e}")

                results = self.processor.post_process_grounded_object_detection(
                    outputs,
                    inputs.input_ids,
                    target_sizes=[image.size[::-1]]
                )[0]

                # threshold ìˆ˜ë™ ì ìš©
                filtered_boxes = []
                filtered_scores = []
                filtered_labels = []

                for box, score, label in zip(results["boxes"], results["scores"], results["labels"]):
                    if float(score) >= box_threshold:
                        filtered_boxes.append(box)
                        filtered_scores.append(score)
                        filtered_labels.append(label)

                # ê²°ê³¼ ë³€í™˜
                if len(filtered_boxes) > 0:
                    detections = self._postprocess_results(
                        boxes=torch.stack(filtered_boxes),
                        scores=torch.stack(filtered_scores),
                        labels=filtered_labels,
                        image_size=image.size
                    )
                else:
                    detections = []

            logger.info(f"âœ… Grounding DINO ì¶”ë¡  ì™„ë£Œ - íƒì§€ëœ ê°ì²´: {len(detections)}ê°œ")

            return {
                "boxes": detections,
                "num_detections": len(detections),
                "task_type": "bbox",
                "model_type": "grounding_dino",
                "text_prompt": text_prompt
            }

        except Exception as e:
            logger.error(f"âŒ Grounding DINO ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(status_code=500, detail=f"ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")

    def _postprocess_results(
        self,
        boxes: torch.Tensor,
        scores: torch.Tensor,
        labels: List[str],
        image_size: tuple
    ) -> List[Dict]:
        """
        Grounding DINO ê²°ê³¼ í›„ì²˜ë¦¬ (Transformers API)

        Args:
            boxes: íƒì§€ëœ ë°•ìŠ¤ (í”½ì…€ ì¢Œí‘œ xyxy format)
            scores: ì‹ ë¢°ë„ ì ìˆ˜
            labels: íƒì§€ëœ í…ìŠ¤íŠ¸ ë ˆì´ë¸”
            image_size: ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (width, height)

        Returns:
            List[Dict]: ë°•ìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        detections = []
        img_width, img_height = image_size

        # Tensorë¥¼ numpyë¡œ ë³€í™˜
        if isinstance(boxes, torch.Tensor):
            boxes = boxes.cpu().numpy()
        if isinstance(scores, torch.Tensor):
            scores = scores.cpu().numpy()

        for box, confidence, label in zip(boxes, scores, labels):
            # í”½ì…€ ì¢Œí‘œ xyxy format
            x_min, y_min, x_max, y_max = box

            # xywh í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            width = x_max - x_min
            height = y_max - y_min

            # ì •ê·œí™”ëœ ì¢Œí‘œ ê³„ì‚°
            x_center_norm = ((x_min + x_max) / 2) / img_width
            y_center_norm = ((y_min + y_max) / 2) / img_height
            width_norm = width / img_width
            height_norm = height / img_height

            detection = {
                "class_id": -1,  # Grounding DINOëŠ” class IDê°€ ì—†ìŒ
                "class_name": label.strip(),
                "confidence": float(confidence),
                "bbox": [float(x_min), float(y_min), float(width), float(height)],
                "normalized_coords": [
                    float(x_center_norm),
                    float(y_center_norm),
                    float(width_norm),
                    float(height_norm)
                ]
            }

            detections.append(detection)

        return detections

    def get_model_info(self) -> Dict[str, Any]:
        """
        Grounding DINO ëª¨ë¸ ì •ë³´ ë°˜í™˜

        Returns:
            Dict[str, Any]: ëª¨ë¸ ë©”íƒ€ë°ì´í„°
        """
        return {
            "model_type": "grounding_dino",
            "task": "detection",
            "framework": "transformers",
            "device": "cuda" if torch.cuda.is_available() else "cpu",
            "is_loaded": self.is_loaded,
            "supports_text_prompt": True,
            "zero_shot": True,
            "model_id": self.model_id,
            "source": "Hugging Face Hub"
        }
