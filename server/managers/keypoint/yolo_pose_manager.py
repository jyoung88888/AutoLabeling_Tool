"""
YOLO Pose Keypoint Detection Model Manager
YOLO Pose í‚¤í¬ì¸íŠ¸ íƒì§€ ëª¨ë¸ ê´€ë¦¬ì
"""
import torch
import logging
import numpy as np
from pathlib import Path
from typing import Dict, Any, Optional, List
from io import BytesIO
from PIL import Image
from fastapi import HTTPException

from ..base_model import BaseModel, ModelType, TaskType

logger = logging.getLogger(__name__)


class YOLOPoseManager(BaseModel):
    """
    YOLO Pose í‚¤í¬ì¸íŠ¸ íƒì§€ ëª¨ë¸ ê´€ë¦¬ì
    ì‚¬ëŒì˜ í¬ì¦ˆ(í‚¤í¬ì¸íŠ¸)ë¥¼ íƒì§€í•©ë‹ˆë‹¤. (COCO 17 keypoints)
    """

    def __init__(self):
        """YOLO Pose ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        super().__init__()
        self.model_type = ModelType.KEYPOINT
        self.task_type = TaskType.KEYPOINT
        self.num_keypoints = 17  # COCO format

        # COCO 17 keypoints ì •ì˜
        self.keypoint_names = [
            "nose",           # 0
            "left_eye",       # 1
            "right_eye",      # 2
            "left_ear",       # 3
            "right_ear",      # 4
            "left_shoulder",  # 5
            "right_shoulder", # 6
            "left_elbow",     # 7
            "right_elbow",    # 8
            "left_wrist",     # 9
            "right_wrist",    # 10
            "left_hip",       # 11
            "right_hip",      # 12
            "left_knee",      # 13
            "right_knee",     # 14
            "left_ankle",     # 15
            "right_ankle"     # 16
        ]

    def load_model(self, model_path: str, **kwargs):
        """
        YOLO Pose ëª¨ë¸ ë¡œë”©

        Args:
            model_path (str): ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (yolov8n-pose.pt ë“±)
            **kwargs: ì¶”ê°€ ì„¤ì •
        """
        try:
            from ultralytics import YOLO

            model_path = Path(model_path)
            if not model_path.is_file():
                raise HTTPException(
                    status_code=404,
                    detail=f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}"
                )

            logger.info(f"ğŸ”„ YOLO Pose ëª¨ë¸ ë¡œë”© ì‹œì‘: {model_path}")
            self.model = YOLO(str(model_path))

            # GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ GPUë¡œ ì´ë™
            if torch.cuda.is_available():
                torch.cuda.set_device(0)
                self.model.to('cuda:0')
                logger.info(f"âœ… YOLO Pose ëª¨ë¸ì„ GPU(cuda:0)ë¡œ ë¡œë“œ")
            else:
                logger.info(f"âœ… YOLO Pose ëª¨ë¸ì„ CPUë¡œ ë¡œë“œ")

            self.is_loaded = True
            logger.info(f"âœ… YOLO Pose ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

            return {
                "success": True,
                "message": f"YOLO Pose model {model_path.name} loaded successfully",
                "num_keypoints": self.num_keypoints
            }

        except Exception as e:
            logger.error(f"âŒ YOLO Pose ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(status_code=500, detail=f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")

    def predict(self, image, **kwargs) -> Dict[str, Any]:
        """
        YOLO Pose í‚¤í¬ì¸íŠ¸ íƒì§€ ì¶”ë¡ 

        Args:
            image: PIL Image, numpy array, ë˜ëŠ” BytesIO
            **kwargs:
                - confidence_threshold (float): ì‹ ë¢°ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.5)
                - imgsz (int): ì¶”ë¡  ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸ê°’: 640)

        Returns:
            Dict[str, Any]: í‚¤í¬ì¸íŠ¸ íƒì§€ ê²°ê³¼
        """
        if not self.validate_model():
            raise HTTPException(status_code=400, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        try:
            # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            confidence_threshold = kwargs.get('confidence_threshold', 0.5)
            imgsz = kwargs.get('imgsz', 640)

            logger.info(f"ğŸ” YOLO Pose ì¶”ë¡  ì‹œì‘ - ì‹ ë¢°ë„: {confidence_threshold}")

            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self._preprocess_image(image)

            # YOLO Pose ì¶”ë¡  ì‹¤í–‰
            results = self.model.predict(
                processed_image,
                imgsz=imgsz,
                conf=confidence_threshold,
                iou=0.5,
                max_det=300,
                verbose=False,
                save=False,
                device=None
            )

            # ê²°ê³¼ í›„ì²˜ë¦¬
            keypoints_data = self._postprocess_results(results[0])

            logger.info(f"âœ… YOLO Pose ì¶”ë¡  ì™„ë£Œ - íƒì§€ëœ ì‚¬ëŒ: {len(keypoints_data)}ëª…")

            return {
                "keypoints": keypoints_data,
                "num_persons": len(keypoints_data),
                "task_type": "keypoint",
                "model_type": "yolo_pose",
                "keypoint_format": "coco_17"
            }

        except Exception as e:
            logger.error(f"âŒ YOLO Pose ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")
            raise HTTPException(status_code=500, detail=f"ì¶”ë¡  ì‹¤íŒ¨: {str(e)}")

    def _preprocess_image(self, image_input):
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬

        Args:
            image_input: BytesIO, PIL Image, numpy array ë“±

        Returns:
            PIL Image: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
        """
        if isinstance(image_input, BytesIO):
            try:
                image_input.seek(0)
                pil_image = Image.open(image_input)

                # ìƒ‰ìƒ ëª¨ë“œ ë³€í™˜
                if pil_image.mode in ('RGBA', 'LA'):
                    rgb_image = Image.new('RGB', pil_image.size, (255, 255, 255))
                    if pil_image.mode == 'RGBA':
                        rgb_image.paste(pil_image, mask=pil_image.split()[-1])
                    else:
                        rgb_image.paste(pil_image.convert('L'))
                    pil_image = rgb_image
                elif pil_image.mode not in ('RGB', 'L'):
                    pil_image = pil_image.convert('RGB')

                logger.info(f"BytesIO â†’ PIL Image ë³€í™˜: {pil_image.mode}, {pil_image.size}")
                return pil_image

            except Exception as e:
                logger.error(f"ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                raise HTTPException(status_code=400, detail=f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

        return image_input

    def _postprocess_results(self, result) -> List[Dict]:
        """
        YOLO Pose ê²°ê³¼ í›„ì²˜ë¦¬

        Args:
            result: YOLO ê²°ê³¼ ê°ì²´

        Returns:
            List[Dict]: í‚¤í¬ì¸íŠ¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        keypoints_data = []

        if not hasattr(result, 'keypoints') or result.keypoints is None:
            logger.info("íƒì§€ëœ í‚¤í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
            return keypoints_data

        if len(result.keypoints) == 0:
            logger.info("íƒì§€ëœ ì‚¬ëŒì´ ì—†ìŠµë‹ˆë‹¤")
            return keypoints_data

        logger.info(f"íƒì§€ëœ ì‚¬ëŒ ìˆ˜: {len(result.keypoints)}")

        # í‚¤í¬ì¸íŠ¸ ë°ì´í„° ì¶”ì¶œ
        kpts_xy = result.keypoints.xy.cpu().numpy()  # (N, 17, 2) - í”½ì…€ ì¢Œí‘œ
        kpts_conf = result.keypoints.conf.cpu().numpy()  # (N, 17) - ì‹ ë¢°ë„

        # ì´ë¯¸ì§€ í¬ê¸° (ì •ê·œí™”ìš©)
        img_height, img_width = result.orig_shape

        for person_idx, (person_kpts, person_conf) in enumerate(zip(kpts_xy, kpts_conf)):
            # ê° ì‚¬ëŒì˜ í‚¤í¬ì¸íŠ¸ ì •ë³´
            keypoints_list = []

            for kpt_idx, (xy, conf) in enumerate(zip(person_kpts, person_conf)):
                x, y = xy
                keypoint_info = {
                    "name": self.keypoint_names[kpt_idx],
                    "x": float(x),
                    "y": float(y),
                    "confidence": float(conf),
                    "normalized_x": float(x / img_width),
                    "normalized_y": float(y / img_height),
                    "visible": conf > 0.5  # ì‹ ë¢°ë„ 0.5 ì´ìƒì´ë©´ ë³´ì„
                }
                keypoints_list.append(keypoint_info)

            # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ (ìˆìœ¼ë©´)
            bbox = None
            if hasattr(result, 'boxes') and result.boxes is not None:
                if len(result.boxes) > person_idx:
                    box = result.boxes[person_idx]
                    xywh = box.xywh[0].cpu().numpy()
                    x_center, y_center, width, height = xywh
                    x = x_center - width / 2
                    y = y_center - height / 2
                    bbox = [float(x), float(y), float(width), float(height)]

            person_data = {
                "person_id": person_idx,
                "keypoints": keypoints_list,
                "num_keypoints": self.num_keypoints,
                "bbox": bbox,
                "avg_confidence": float(np.mean(person_conf))
            }

            keypoints_data.append(person_data)

        return keypoints_data

    def get_model_info(self) -> Dict[str, Any]:
        """
        YOLO Pose ëª¨ë¸ ì •ë³´ ë°˜í™˜

        Returns:
            Dict[str, Any]: ëª¨ë¸ ë©”íƒ€ë°ì´í„°
        """
        return {
            "model_type": "yolo_pose",
            "task": "keypoint",
            "framework": "ultralytics",
            "device": "cuda" if torch.cuda.is_available() else "cpu",
            "is_loaded": self.is_loaded,
            "num_keypoints": self.num_keypoints,
            "keypoint_format": "coco_17",
            "keypoint_names": self.keypoint_names
        }
